{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "682c3d7b-7b6a-423d-ae37-68644755c3d5",
   "metadata": {},
   "source": [
    "# dataloaders\n",
    "\n",
    "> Module containing helper functions and classes around dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1cf4a2-c9ca-452a-b378-69441144ee85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adb3934-ae03-437a-93bb-89e33d4c2784",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from functools import partial\n",
    "\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483cb732-4797-4119-ad97-9ec0812aa843",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "def hf_ds_collate_fn(data, flatten=True):\n",
    "    '''\n",
    "    Collation function for building a PyTorch DataLoader from a a huggingface dataset.\n",
    "    Tries to put all items from an entry into the dataset to tensor.\n",
    "    PIL images are converted to tensor, either flattened or not \n",
    "    '''\n",
    "\n",
    "    def to_tensor(i, flatten):\n",
    "        if isinstance(i, PIL.Image.Image):\n",
    "            if flatten:\n",
    "                return torch.flatten(TF.to_tensor(i))\n",
    "            return TF.to_tensor(i)\n",
    "        else:\n",
    "            return torch.tensor(i)\n",
    "    \n",
    "    to_tensor = partial(to_tensor, flatten=flatten)      # partially apply to_tensor() with flatten arg\n",
    "    data = [map(to_tensor, el.values()) for el in data]  # map each item from a dataset entry through to_tensor()\n",
    "    data = zip(*data)                                    # zip data of any length not just (x,y) but also (x,y,z)\n",
    "    return (torch.stack(i) for i in data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bbb8c8-7402-4c71-804d-ef4312336588",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class DataLoaders:\n",
    "    def __init__(self, train, valid):\n",
    "        '''Class that exposes two PyTorch dataloaders as train and valid arguments'''\n",
    "        self.train = train\n",
    "        self.valid = valid\n",
    "    \n",
    "    @classmethod\n",
    "    def _get_dls(cls, train_ds, valid_ds, bs, collate_fn, **kwargs):\n",
    "        '''Helper function returning 2 PyTorch Dataloaders as a tuple for 2 Datasets. **kwargs are passed to the DataLoader'''\n",
    "        return (DataLoader(train_ds, batch_size=bs, shuffle=True, collate_fn=collate_fn, **kwargs),\n",
    "                DataLoader(valid_ds, batch_size=bs*2, collate_fn=collate_fn, **kwargs))\n",
    "        \n",
    "    @classmethod\n",
    "    def from_hf_dd(cls, dd, batch_size, collate_fn=hf_ds_collate_fn, **kwargs):\n",
    "        '''Factory method to create a Dataloaders object for a Huggingface Dataset dict,\n",
    "        uses the `hf_ds_collate_func` collation function by default, **kwargs are passes to the DataLoaders'''\n",
    "        return cls(*cls._get_dls(*dd.values(), batch_size, collate_fn, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586dfd19-2562-409e-acc5-4af701e7bca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763c49d9-2ee8-42ab-8e5b-0c873b3ff758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/lucasvw/nntrain/blob/main/nntrain/dataloaders.py#L49){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DataLoaders.from_hf_dd\n",
       "\n",
       ">      DataLoaders.from_hf_dd (dd, batch_size, collate_fn=<function\n",
       ">                              hf_ds_collate_fn>, **kwargs)\n",
       "\n",
       "Factory method to create a Dataloaders object for a Huggingface Dataset dict,\n",
       "uses the `hf_ds_collate_func` collation function by default, **kwargs are passes to the DataLoaders"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/lucasvw/nntrain/blob/main/nntrain/dataloaders.py#L49){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DataLoaders.from_hf_dd\n",
       "\n",
       ">      DataLoaders.from_hf_dd (dd, batch_size, collate_fn=<function\n",
       ">                              hf_ds_collate_fn>, **kwargs)\n",
       "\n",
       "Factory method to create a Dataloaders object for a Huggingface Dataset dict,\n",
       "uses the `hf_ds_collate_func` collation function by default, **kwargs are passes to the DataLoaders"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(DataLoaders.from_hf_dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75647782-fa35-4525-8740-b8f436efe5f0",
   "metadata": {},
   "source": [
    "Example usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5810dd-f1b8-4e22-bd05-66a64f646c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset,load_dataset_builder\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1b2516-1d0c-4fdb-b357-bbd0e0412ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "485c61ab8e2f4d0185155a0f50d59669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da786239e8bf44b88b543d6c7ed3b0b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/1.36k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset fashion_mnist/fashion_mnist (download: 29.45 MiB, generated: 34.84 MiB, post-processed: Unknown size, total: 64.29 MiB) to /root/.cache/huggingface/datasets/fashion_mnist/fashion_mnist/1.0.0/8d6c32399aa01613d96e2cbc9b13638f359ef62bb33612b077b4c247f6ef99c1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9310b2f7368b4c1096a8dcadc00a0d91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30174f723b464eed931229a45e45d557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/26.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4498552c79544a5975e1d883087af23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/29.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcad7198831c4c50a735482ae4dcbdf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/4.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c30d10721e4baebe79ee968f9c0a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/5.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ed0bb271dbf472393b4e81ca6c1f878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/60000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset fashion_mnist downloaded and prepared to /root/.cache/huggingface/datasets/fashion_mnist/fashion_mnist/1.0.0/8d6c32399aa01613d96e2cbc9b13638f359ef62bb33612b077b4c247f6ef99c1. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7fa815ba0f4d678430f811452f47d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "name = \"fashion_mnist\"\n",
    "ds_builder = load_dataset_builder(name)\n",
    "ds_hf = load_dataset(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea51006a-0f60-4b78-af1c-0421483dbdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 | train_loss=2.185 | valid_loss=2.070 | acc=0.407\n"
     ]
    }
   ],
   "source": [
    "def accuracy(preds, targs):\n",
    "    return (preds.argmax(dim=1) == targs).float().mean() \n",
    "\n",
    "def fit(epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()                                       \n",
    "        n_t = train_loss_s = 0                              \n",
    "        for xb, yb in dls.train:\n",
    "            preds = model(xb)\n",
    "            train_loss = loss_func(preds, yb)\n",
    "            train_loss.backward()\n",
    "            \n",
    "            n_t += len(xb)\n",
    "            train_loss_s += train_loss.item() * len(xb)\n",
    "            \n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        \n",
    "        model.eval()                                        \n",
    "        n_v = valid_loss_s = acc_s = 0                      \n",
    "        for xb, yb in dls.valid: \n",
    "            with torch.no_grad():                           \n",
    "                preds = model(xb)\n",
    "                valid_loss = loss_func(preds, yb)\n",
    "                \n",
    "                n_v += len(xb)\n",
    "                valid_loss_s += valid_loss.item() * len(xb)\n",
    "                acc_s += accuracy(preds, yb) * len(xb)\n",
    "        \n",
    "        train_loss = train_loss_s / n_t                     \n",
    "        valid_loss = valid_loss_s / n_v\n",
    "        acc = acc_s / n_v\n",
    "        print(f'{epoch=} | {train_loss=:.3f} | {valid_loss=:.3f} | {acc=:.3f}')\n",
    "\n",
    "def get_model_opt():\n",
    "    layers = [nn.Linear(n_in, n_h), nn.ReLU(), nn.Linear(n_h, n_out)]\n",
    "    model = nn.Sequential(*layers)\n",
    "    \n",
    "    opt = torch.optim.SGD(model.parameters(), lr)\n",
    "    \n",
    "    return model, opt\n",
    "\n",
    "n_in  = 28*28\n",
    "n_h   = 50\n",
    "n_out = 10\n",
    "lr    = 0.01\n",
    "bs    = 1024\n",
    "loss_func = F.cross_entropy\n",
    "\n",
    "model, opt = get_model_opt()\n",
    "\n",
    "dls = DataLoaders.from_hf_dd(ds_hf, bs)\n",
    "\n",
    "fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886e47c4-2441-4081-84bb-14e680565c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de32fed-ca6d-4231-a657-5b45e56baff8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
