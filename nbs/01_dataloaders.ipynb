{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddbd6117-f9c9-40fd-902e-3bd4201b35f7",
   "metadata": {},
   "source": [
    "## First exports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18cfe11-c26d-4d2d-99de-0dc464c58895",
   "metadata": {},
   "source": [
    "When exporting code to a module with `nbdev` the first thing we need to do is declare the `default_exp` directive. This makes sure that when we run the export, the module will be exported to `dataloaders.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1cf4a2-c9ca-452a-b378-69441144ee85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adb3934-ae03-437a-93bb-89e33d4c2784",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483cb732-4797-4119-ad97-9ec0812aa843",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "def hf_ds_collate_func(data):\n",
    "    '''\n",
    "    Collation function for building a PyTorch DataLoader from a a huggingface dataset.\n",
    "    Tries to put all items from an entry into the dataset to tensor.\n",
    "    PIL images are converted to tensor.\n",
    "    '''\n",
    "\n",
    "    def to_tensor(i):\n",
    "        if isinstance(i, PIL.Image.Image):\n",
    "            return TF.to_tensor(i).view(-1)\n",
    "        else:\n",
    "            return torch.tensor(i)\n",
    "    \n",
    "    data = [map(to_tensor, el.values()) for el in data]  # map each item from a dataset entry through to_tensor()\n",
    "    data = zip(*data)                                    # zip data of any length not just (x,y) but also (x,y,z)\n",
    "    return (torch.stack(i) for i in data)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bbb8c8-7402-4c71-804d-ef4312336588",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class DataLoaders:\n",
    "    def __init__(self, train, valid):\n",
    "        self.train = train\n",
    "        self.valid = valid\n",
    "    \n",
    "    @classmethod\n",
    "    def _get_dls(cls, train_ds, valid_ds, bs, collate_fn):\n",
    "        return (DataLoader(train_ds, batch_size=bs, shuffle=True, collate_fn=collate_fn),\n",
    "                DataLoader(valid_ds, batch_size=bs*2, collate_fn=collate_fn))\n",
    "        \n",
    "    @classmethod\n",
    "    def from_hf_dd(cls, dd, batch_size):\n",
    "        return cls(*cls._get_dls(*dd.values(), batch_size, hf_ds_collate_func))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea51006a-0f60-4b78-af1c-0421483dbdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()                                       \n",
    "        n_t = train_loss_s = 0                              \n",
    "        for xb, yb in dls.train:\n",
    "            preds = model(xb)\n",
    "            train_loss = loss_func(preds, yb)\n",
    "            train_loss.backward()\n",
    "            \n",
    "            n_t += len(xb)\n",
    "            train_loss_s += train_loss.item() * len(xb)\n",
    "            \n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        \n",
    "        model.eval()                                        \n",
    "        n_v = valid_loss_s = acc_s = 0                      \n",
    "        for xb, yb in dls.valid: \n",
    "            with torch.no_grad():                           \n",
    "                preds = model(xb)\n",
    "                valid_loss = loss_func(preds, yb)\n",
    "                \n",
    "                n_v += len(xb)\n",
    "                valid_loss_s += valid_loss.item() * len(xb)\n",
    "                acc_s += accuracy(preds, yb) * len(xb)\n",
    "        \n",
    "        train_loss = train_loss_s / n_t                     \n",
    "        valid_loss = valid_loss_s / n_v\n",
    "        acc = acc_s / n_v\n",
    "        print(f'{epoch=} | {train_loss=:.3f} | {valid_loss=:.3f} | {acc=:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c97699-a441-41ab-a146-8616ca2710ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders.from_hf_dd(ds_hf, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2128fd28-f5a0-482c-9b61-f9a043535b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 | train_loss=2.175 | valid_loss=2.050 | acc=0.406\n",
      "epoch=1 | train_loss=1.917 | valid_loss=1.780 | acc=0.536\n",
      "epoch=2 | train_loss=1.651 | valid_loss=1.532 | acc=0.616\n",
      "epoch=3 | train_loss=1.427 | valid_loss=1.340 | acc=0.637\n",
      "epoch=4 | train_loss=1.262 | valid_loss=1.203 | acc=0.648\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model_opt()\n",
    "\n",
    "fit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886e47c4-2441-4081-84bb-14e680565c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de32fed-ca6d-4231-a657-5b45e56baff8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
